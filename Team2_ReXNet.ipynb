{"cells":[{"cell_type":"markdown","metadata":{"id":"qP_SVFJKUCsK"},"source":["2022_봄학기_실전기계학습_Competition Guide Code\n","\n","1. Pretraioned Model 사용금지\n","2. Personal Data 사용금지\n","3. Epoch 50회까지 제한\n","4. Test Data로 Train 금지\n","5. Model Param 5M이상 금지\n","6. 최종 제출 모델 파일로 조교가 재현시 비슷한 성능이 나오지 않은 경우\n","Cheating으로 간주\n","7. 기타 궁금한 사항들(간단하거나 쉬운 것도 괜찮습니다)은 조교에게 질문주셔요\n","- Email\n","- 전자정보대학 325-1 방문"]},{"cell_type":"markdown","metadata":{"id":"_gR35w-rUKib"},"source":["아래 코드는 각종 Library를 선언하는 부분입니다."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-07T09:12:44.352628Z","iopub.status.busy":"2022-06-07T09:12:44.352336Z","iopub.status.idle":"2022-06-07T09:12:59.232210Z","shell.execute_reply":"2022-06-07T09:12:59.230477Z","shell.execute_reply.started":"2022-06-07T09:12:44.352567Z"},"id":"B19ve3iGS8W5","trusted":true},"outputs":[],"source":["# 캐글\n","#!pip install addict"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-07T09:12:59.238358Z","iopub.status.busy":"2022-06-07T09:12:59.237691Z","iopub.status.idle":"2022-06-07T09:12:59.246100Z","shell.execute_reply":"2022-06-07T09:12:59.244845Z","shell.execute_reply.started":"2022-06-07T09:12:59.238314Z"},"id":"B6MSeB9aTSVX","outputId":"f0ba4b3d-f1d2-45da-a90e-695b5c2037a5","trusted":true},"outputs":[],"source":["# 코랩\n","from google.colab import drive\n","drive.mount('/content/drive')\n","#!pip install addict\n","#!pip uninstall opencv-python-headless==4.5.5.62\n","#!pip install opencv-python-headless==4.5.2.52\n","#!pip install git+https://github.com/albumentations-team/albumentations"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-06-09T06:47:27.751097Z","iopub.status.busy":"2022-06-09T06:47:27.750515Z","iopub.status.idle":"2022-06-09T06:47:32.232020Z","shell.execute_reply":"2022-06-09T06:47:32.230929Z","shell.execute_reply.started":"2022-06-09T06:47:27.751012Z"},"id":"luPwOB3RJPDE","trusted":true},"outputs":[],"source":["# importing all the libraries we need\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import sys\n","import os\n","import time\n","import random \n","import pandas as pd\n","import torch\n","from torch import nn, cuda, optim\n","from torchvision import models,transforms,datasets\n","from torch.utils.data import Dataset, DataLoader,random_split\n","from PIL import Image\n","import seaborn as sns\n","import torch.nn.functional as F\n","import albumentations as A\n","#from addict import Dict"]},{"cell_type":"markdown","metadata":{"id":"6V1ASuR9Wu36"},"source":["Train 시 로그를 보여주기위해 선언한 Class입니다."]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-06-09T06:47:34.728748Z","iopub.status.busy":"2022-06-09T06:47:34.728008Z","iopub.status.idle":"2022-06-09T06:47:34.744092Z","shell.execute_reply":"2022-06-09T06:47:34.742749Z","shell.execute_reply.started":"2022-06-09T06:47:34.728702Z"},"id":"dU1V5kuUDjc1","trusted":true},"outputs":[],"source":["train_transform = transforms.Compose([transforms.RandomRotation(15),transforms.RandomHorizontalFlip(),\n","                                      transforms.ToTensor(),transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n","val_transform = transforms.Compose([transforms.RandomRotation(15),transforms.RandomHorizontalFlip(),\n","                                      transforms.ToTensor(),transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-06-09T06:47:36.437205Z","iopub.status.busy":"2022-06-09T06:47:36.436776Z","iopub.status.idle":"2022-06-09T06:47:36.453629Z","shell.execute_reply":"2022-06-09T06:47:36.452450Z","shell.execute_reply.started":"2022-06-09T06:47:36.437171Z"},"id":"6CFoELagaX7D","trusted":true},"outputs":[],"source":["class AverageMeter(object):\n","    r\"\"\"Computes and stores the average and current value\n","    \"\"\"\n","    def __init__(self, name, fmt=':f'):\n","        self.name = name\n","        self.fmt = fmt\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","    def __str__(self):\n","        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n","        return fmtstr.format(**self.__dict__)\n","\n","\n","class ProgressMeter(object):\n","    def __init__(self, num_batches, *meters, prefix=\"\"):\n","        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n","        self.meters = meters\n","        self.prefix = prefix\n","\n","    def print(self, batch):\n","        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n","        entries += [str(meter) for meter in self.meters]\n","        print('\\t'.join(entries))\n","\n","    def _get_batch_fmtstr(self, num_batches):\n","        num_digits = len(str(num_batches // 1))\n","        fmt = '{:' + str(num_digits) + 'd}'\n","        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n","\n","\n","def accuracy(output, target, topk=(1,)):\n","    r\"\"\"Computes the accuracy over the $k$ top predictions for the specified values of k\n","    \"\"\"\n","    with torch.no_grad():\n","        maxk = max(topk)\n","        batch_size = target.size(0)\n","\n","        # _, pred = output.topk(maxk, 1, True, True)\n","        # pred = pred.t()\n","        # correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        # faster topk (ref: https://github.com/pytorch/pytorch/issues/22812)\n","        _, idx = output.sort(descending=True)\n","        pred = idx[:,:maxk]\n","        pred = pred.t()\n","        correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        res = []\n","        for k in topk:\n","            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n","            res.append(correct_k.mul_(100.0 / batch_size))\n","        return res"]},{"cell_type":"markdown","metadata":{"id":"RhAYLoAqV5Lx"},"source":["위에서 정의한 Model을 만들고 Parameter수를 체크한 후\n","5M 미만인 경우 GPU에서 정상 사용되는지 확인하는 부분입니다."]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-06-09T06:47:51.302309Z","iopub.status.busy":"2022-06-09T06:47:51.301956Z","iopub.status.idle":"2022-06-09T06:48:04.248135Z","shell.execute_reply":"2022-06-09T06:48:04.247313Z","shell.execute_reply.started":"2022-06-09T06:47:51.302280Z"},"id":"s7hWsvesMyX0","outputId":"f09cad21-012b-422d-ae60-c1e2ee22b7fd","trusted":true},"outputs":[],"source":["data_dir = '../input/100-bird-species/train'\n","data = datasets.ImageFolder(data_dir)\n","train_size = int(len(data)*0.95)\n","val_size = int((len(data)-train_size))\n","train_data,val_data = random_split(data,[train_size,val_size])\n","torch.manual_seed(3334)\n","print(f'train size: {len(train_data)}\\nval size: {len(val_data)}')\n","\n","train_data.dataset.transform = train_transform\n","val_data.dataset.transform = val_transform\n","batch_size = 16\n","train_loader = DataLoader(train_data,batch_size=batch_size,shuffle=True, num_workers = 2)\n","val_loader = DataLoader(val_data,batch_size=batch_size,shuffle=False, num_workers = 2)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-06-09T06:48:25.236133Z","iopub.status.busy":"2022-06-09T06:48:25.235731Z","iopub.status.idle":"2022-06-09T06:48:25.268817Z","shell.execute_reply":"2022-06-09T06:48:25.268005Z","shell.execute_reply.started":"2022-06-09T06:48:25.236103Z"},"id":"N-B0lvE1G8me","trusted":true},"outputs":[],"source":["import sys\n","sys.path.insert(1, \"../input/ReXNet\")\n","import rexnetv1"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-06-09T06:48:30.163364Z","iopub.status.busy":"2022-06-09T06:48:30.162960Z","iopub.status.idle":"2022-06-09T06:48:32.965547Z","shell.execute_reply":"2022-06-09T06:48:32.964692Z","shell.execute_reply.started":"2022-06-09T06:48:30.163330Z"},"id":"v-9HtiFWD_Au","outputId":"9806d670-418f-4ae8-a1e4-fd00edb3c530","trusted":true},"outputs":[],"source":["# loading the model architecture\n","model = rexnetv1.ReXNetV1(width_mult=1.12, dropout_ratio=0.5, classes=400).cuda()\n","\n","# Check number of parameters your model\n","pytorch_total_params = sum(p.numel() for p in model.parameters())\n","print(f\"Number of parameters: {pytorch_total_params}\")\n","if int(pytorch_total_params) > 5000000:\n","    print('Your model has the number of parameters more than 5 millions..')\n","    sys.exit()\n","    \n","device = torch.device('cuda:0' if cuda.is_available() else 'cpu')\n","model.to(device)\n","print(device)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-06-09T06:48:35.277297Z","iopub.status.busy":"2022-06-09T06:48:35.276926Z","iopub.status.idle":"2022-06-09T06:48:35.285140Z","shell.execute_reply":"2022-06-09T06:48:35.284012Z","shell.execute_reply.started":"2022-06-09T06:48:35.277268Z"},"id":"2wTlS7qfD_4-","trusted":true},"outputs":[],"source":["# optimizer = optim.Adam(model.parameters(), lr=0.0002, weight_decay=0.0005)\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.02, momentum=0.9, nesterov=True, weight_decay=0.0005)\n","scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones = [20, 30, 35, 40, 43, 47], gamma = 0.5)\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-06-09T06:48:40.823109Z","iopub.status.busy":"2022-06-09T06:48:40.822722Z","iopub.status.idle":"2022-06-09T06:48:40.842720Z","shell.execute_reply":"2022-06-09T06:48:40.841823Z","shell.execute_reply.started":"2022-06-09T06:48:40.823079Z"},"id":"lOGAV04NJb3l","trusted":true},"outputs":[],"source":["def fit(model,criterion,optimizer,num_epochs=10):\n","    print_freq = 200\n","    start = time.time()\n","    best_model = model.state_dict()\n","    best_acc = 0\n","    train_loss_over_time = []\n","    val_loss_over_time = []\n","    train_acc_over_time = []\n","    val_acc_over_time = []\n","\n","\n","    # each epoch has a training and validation phase\n","    for epoch in range(num_epochs):\n","        \n","        print(\"\\n----- epoch: {}, lr: {} -----\".format(epoch, optimizer.param_groups[0][\"lr\"]))\n","        batch_time = AverageMeter('Time', ':6.3f')\n","        acc = AverageMeter('Accuracy', ':.4e')\n","        progress = ProgressMeter(len(train_loader), batch_time, acc, prefix=\"Epoch: [{}]\".format(epoch))\n","\n","        for phase in ['train','val']:\n","            \n","            if phase == 'train':\n","                data_loader = train_loader\n","                model.train()                    # set the model to train mode\n","                end = time.time()\n","\n","            else:\n","                data_loader = val_loader\n","                model.eval()                    # set the model to evaluate mode\n","                end = time.time()\n","            \n","                \n","            running_loss = 0.0\n","            running_corrects = 0.0\n","            \n","            # iterate over the data\n","            for i,(inputs,labels) in enumerate(data_loader):\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","                \n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","                \n","                # forward\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _,pred = torch.max(outputs,dim=1)\n","                    loss = criterion(outputs,labels)\n","                    \n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","                \n","                # calculating the loss and accuracy\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(pred == labels.data)\n","\n","                epoch_acc = (running_corrects.double()/len(train_data)).cpu().numpy()\n","                acc.update(epoch_acc.item(), inputs.size(0))\n","                \n","                if phase == 'train':                          \n","                    batch_time.update(time.time() - end)\n","                    end = time.time()\n","\n","                    if i % print_freq == 0:\n","                        progress.print(i)  \n","\n","            if phase == 'train':\n","\n","                epoch_loss = running_loss/len(train_data)\n","                train_loss_over_time.append(epoch_loss)\n","                epoch_acc = (running_corrects.double()/len(train_data)).cpu().numpy()\n","                train_acc_over_time.append(epoch_acc)\n","\n","\n","            else:\n","                epoch_loss = running_loss/len(val_data)\n","                val_loss_over_time.append(epoch_loss)\n","                epoch_acc = (running_corrects.double()/len(val_data)).cpu().numpy()\n","                val_acc_over_time.append(epoch_acc)\n","          \n","\n","            print(f'{phase} loss: {epoch_loss:.3f}, acc: {epoch_acc:.3f}')\n","            \n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                torch.save(model.state_dict(), 'model_best.pt')\n","            \n","            torch.save(model.state_dict(),f'model_latest{epoch_acc}.pt')\n","            \n","        scheduler.step()\n","        print('-'*60)\n","    print('\\n') \n","    elapsed_time = time.time() - start\n","    print('==> {:.2f} seconds to train this epoch\\n'.format(elapsed_time))\n","    print(f'best accuracy: {best_acc:.3f}')\n","\n","\n","    # load best model weights\n","    model.load_state_dict(best_model)\n","    loss = {'train':train_loss_over_time, 'val':val_loss_over_time}\n","    acc = {'train':train_acc_over_time, 'val':val_acc_over_time}\n","\n","    return model,loss, acc"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"Wyn-HOyzJbzF","outputId":"01438346-77ac-4b30-e6f2-b10c706d61f9","trusted":true},"outputs":[],"source":["# training the model\n","# trained for 5 epochs then for 3 epochs then 2\n","epochs = 50\n","history, loss, acc = fit(model, criterion, optimizer, num_epochs = epochs)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-06-09T11:18:50.884713Z","iopub.status.busy":"2022-06-09T11:18:50.884123Z","iopub.status.idle":"2022-06-09T11:18:51.289507Z","shell.execute_reply":"2022-06-09T11:18:51.288458Z","shell.execute_reply.started":"2022-06-09T11:18:50.884667Z"},"id":"GnwWrXb5Jbwk","trusted":true},"outputs":[],"source":["# plotting the loss and accuracy curve for each phase\n","train_loss = loss['train']\n","val_loss = loss['val']\n","train_acc = acc['train']\n","val_acc = acc['val']\n","\n","epochs_range = range(50)\n","plt.figure(figsize=(20,10))\n","\n","plt.subplot(1,2,1)\n","plt.ylim(0,10)\n","plt.xlim(0,50)\n","plt.plot(epochs_range, train_loss, label='train_loss')\n","plt.plot(epochs_range, val_loss, label='val_loss')\n","plt.legend(loc=0)\n","plt.title('Loss')\n","\n","plt.subplot(1,2,2)\n","plt.plot(epochs_range, train_acc ,label='train_acc')\n","plt.plot(epochs_range, val_acc, label='val_acc')\n","plt.legend(loc=0)\n","plt.ylim(0,1)\n","plt.xlim(0,50)\n","plt.title('Accuracy')"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2022-06-09T11:19:19.278503Z","iopub.status.busy":"2022-06-09T11:19:19.278113Z","iopub.status.idle":"2022-06-09T11:19:20.882858Z","shell.execute_reply":"2022-06-09T11:19:20.882027Z","shell.execute_reply.started":"2022-06-09T11:19:19.278473Z"},"id":"6HIGgFXDEDUt","outputId":"aa94fea1-d573-482d-f408-493cd038234b","trusted":true},"outputs":[],"source":["seed = 0\n","torch.manual_seed(seed)\n","if cuda:\n","    torch.cuda.manual_seed(seed)\n","\n","torch.manual_seed(3334)\n","test_transform = transforms.Compose([transforms.RandomRotation(15),transforms.RandomHorizontalFlip(),\n","                                    transforms.ToTensor(),\n","                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n","\n","\n","# splitting the data into train/validation/test sets\n","test_data_dir = '../input/birddata/test'\n","_data = datasets.ImageFolder(test_data_dir)\n","test1_size = int(len(_data)*1)\n","test2_size = int((len(_data)-test1_size))\n","test_data, test2_data = torch.utils.data.random_split(_data,[test1_size, test2_size])\n","torch.manual_seed(3334)\n","\n","print(f'test size: {len(test_data)}')\n","\n","test_data.dataset.transform = test_transform\n","batch_size = 512\n","test_loader = DataLoader(test_data, batch_size = batch_size, shuffle = False)\n","print(test_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-09T11:47:20.131678Z","iopub.status.busy":"2022-06-09T11:47:20.131148Z"},"id":"KXCheI-dOf9U","outputId":"3a6d05ab-ad98-45ab-c5c9-e503b15e61de","trusted":true},"outputs":[],"source":["import itertools\n","# testing how good the model is\n","def evaluate(model,criterion):\n","    model.eval()       # setting the model to evaluate mode\n","    preds = []\n","    Category = []\n","    \n","    test_model = rexnetv1.ReXNetV1(width_mult=1.12, dropout_ratio=0.5, classes=400).cuda()\n","    test_model.load_state_dict(torch.load('./model_best.pt'))\n","    for inputs, label_ in test_loader:\n","        inputs = inputs.to(device)\n","        labels = label_.to(device)\n","        # predicting\n","        with torch.no_grad():\n","\n","            outputs = test_model(inputs)\n","            _,pred = torch.max(outputs,dim=1)\n","            preds.append(pred)\n","\n","    category = [t.cpu().numpy() for t in preds]\n","    \n","    t_category = list(itertools.chain(*category))\n","   \n","    Id = list(range(0, len(t_category)))\n","\n","    prediction = {\n","      'Id': Id,\n","      'Category': t_category \n","    }\n","\n","    prediction_df = pd.DataFrame(prediction, columns=['Id','Category'])\n","    #저장경로는 변경하셔도 됩니다.\n","    prediction_df.to_csv('prediction.csv', index=False)\n","\n","    print('Done!!')\n","        \n","    return preds\n","\n","# testing the model\n","predictions = evaluate(model, criterion)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
